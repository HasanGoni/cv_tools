{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from fastcore.all import *\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Union, Dict, List\n",
    "#import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import (\n",
    "    label, binary_dilation, binary_erosion,label,\n",
    "    )\n",
    "from skimage.color import label2rgb\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_name_ = np.vectorize(lambda x: x.name)\n",
    "dpi = mpl.rcParams['figure.dpi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def label_mask(\n",
    "        mask:np.ndarray\n",
    "        )->np.ndarray:\n",
    "    \"Label connected components in a binary mask\"\n",
    "    try: \n",
    "        labels, num_labels = label(mask)\n",
    "        return labels, num_labels\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_labeled_mask(\n",
    "        msk_path):\n",
    "    \n",
    "    msk_img = cv2.imread(str(msk_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    labels, num_labels = label_mask(msk_img)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.imshow(labels)\n",
    "    # Annotate each object with its label number\n",
    "    ax.set_facecolor('black')\n",
    "    for i in range(1, num_labels + 1):\n",
    "        y, x = np.where(labels == i)\n",
    "        centroid = (x.mean(), y.mean())\n",
    "        ax.text(centroid[0], centroid[1], str(i), color='white', ha='center', va='center', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    return labels, num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def write_new_mask(\n",
    "                     new_lb, # labeled masks\n",
    "                     new_mask_path, # path to save the new mask\n",
    "                     fn # name of the image\n",
    "                     ):\n",
    "    'Write mask to new_mask_path'\n",
    "    new_lbl = new_lb.astype(np.uint8)\n",
    "    new_lbl = np.where(new_lbl > .9, 255, 0)\n",
    "    cv2.imwrite(f'{new_mask_path}/{fn}', new_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_object_from_mask(\n",
    "                           mask:np.ndarray,\n",
    "                           object_id_list:List[int]\n",
    "                           ):\n",
    "    \"\"\"Remove object from mask.\"\"\"\n",
    "\n",
    "    for i in object_id_list:\n",
    "        mask[mask == i] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_img(\n",
    "    im_path:Union[str, Path],\n",
    "    cv:bool=True,\n",
    "    gray:bool=True\n",
    "    ):\n",
    "    'Read image from name could be open cv or pil image'\n",
    "    if cv:\n",
    "        if gray:\n",
    "            return cv2.imread(f'{im_path}', cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            return cv2.cvtColor(cv2.imread(f'{im_path}'), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return Image.open(im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_(\n",
    "    im_path:Union[str, np.ndarray]\n",
    "    ):\n",
    "    'Showing an image could be image or str, '\n",
    "\n",
    "    if isinstance(im_path,str) or isinstance(im_path, Path):\n",
    "        im = Image.open(im_path)\n",
    "        fig, ax = plt.subplots(figsize= (im.size[0]/dpi, im.size[1]/dpi))\n",
    "        ax.imshow(im)\n",
    "        ax.axis('off')\n",
    "    elif isinstance(im_path, list):\n",
    "            for i in im_path:\n",
    "                if isinstance(i, str) or isinstance(i, Path):\n",
    "                    im = Image.open(i)\n",
    "                    h, w = im.size\n",
    "                    fig, ax = plt.subplots(figsize= (w/dpi, h/dpi))\n",
    "                    ax.imshow(i)\n",
    "                    ax.axis('off')\n",
    "                elif isinstance(i, np.ndarray):\n",
    "                    h, w = i.shape[0], i.shape[1]\n",
    "                    fig, ax = plt.subplots(figsize= (w/dpi, h/dpi))\n",
    "                    ax.imshow(i)\n",
    "                    ax.axis('off')\n",
    "                    \n",
    "                    \n",
    "    else: \n",
    "        h, w = im_path.shape[0], im_path.shape[1]\n",
    "        fig, ax = plt.subplots(figsize= (w/dpi, h/dpi))\n",
    "        im = im_path\n",
    "        ax.imshow(im)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#def normalize(\n",
    "              #image:Union[np.ndarray, tf.Tensor], \n",
    "              #min=0):\n",
    "    #def _normalize(im):\n",
    "        #img = tf.cast(im, tf.float32)\n",
    "        #return img / 255.0\n",
    "\n",
    "    #if min == 0:\n",
    "        #return _normalize(image)\n",
    "    #else:\n",
    "        #return (_normalize(image) * 2.0) -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def center_crop(\n",
    "        image:Image,# not open cv but PIL Image \n",
    "        desired_width:int=1632,\n",
    "        desired_height:int=1152,\n",
    "        height_offset:int=-50,\n",
    "        width_offset:int=-70,\n",
    "        cv:bool=True\n",
    "        ):\n",
    "    # Get the current size of the image\n",
    "    width, height = image.size\n",
    "\n",
    "    # Calculate the coordinates of the center of the image\n",
    "    center_x = (width // 2 + (width_offset))\n",
    "    center_y = (height // 2 + (height_offset))\n",
    "\n",
    "    # Calculate the coordinates of the top-left corner of the crop\n",
    "    left = center_x - desired_width // 2\n",
    "    top = center_y - desired_height // 2\n",
    "\n",
    "    # Calculate the coordinates of the bottom-right corner of the crop\n",
    "    right = center_x + desired_width // 2\n",
    "    bottom = center_y + desired_height // 2\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "    #print(f'cropped_image size = {cropped_image.size}')\n",
    "    if cv:\n",
    "        return np.array(cropped_image)\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def overlay_mask(\n",
    "        im_path:Union[str,Path],\n",
    "        msk_path:Union[str,Path], \n",
    "        overlay_clr:Tuple[int, int, int]=(0, 1, 0), # color\n",
    "        scale:int=1, # to scale the image \n",
    "        alpha:float=0.5, # visibility\n",
    "        ):\n",
    "    'Creaete a overlay image from image and mask'\n",
    "    # Read the grayscale image\n",
    "    gray_img = cv2.imread(f'{im_path}', cv2.IMREAD_GRAYSCALE)\n",
    "    if gray_img is None:\n",
    "        raise ValueError(\"Could not read the grayscale image\")\n",
    "\n",
    "    # Read the mask image\n",
    "    mask_img = cv2.imread(f'{msk_path}', cv2.IMREAD_GRAYSCALE)\n",
    "    mask_img = mask_img.astype(bool)\n",
    "    if mask_img is None:\n",
    "        raise ValueError(\"Could not read the mask image\")\n",
    "\n",
    "    # Check if dimensions of both images are the same\n",
    "    if gray_img.shape != mask_img.shape:\n",
    "        raise ValueError(\"Dimensions of grayscale image and mask do not match\")\n",
    "\n",
    "    # Convert image to 3 channels\n",
    "    rgb_img = np.stack([gray_img]*3, axis=-1)/255\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(rgb_img)\n",
    "\n",
    "    clrd_overlay = np.zeros_like(rgb_img)\n",
    "    clrd_overlay[mask_img]=overlay_clr\n",
    "    ax.imshow(clrd_overlay, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def overlay_mask_border_on_image(\n",
    "        im_path: Union[Path, str],\n",
    "        msk_path: Union[Path, str],\n",
    "        save_new_img_path:Union[Path,str]=None,\n",
    "        save_overlay_img_path:Union[Path,str]=None,\n",
    "        new_img:Union[List, np.ndarray, None] = None,\n",
    "        scale_:int=1,\n",
    "        border_color: Tuple[int, int, int] = (0, 1, 0),\n",
    "        border_width: int = 1,\n",
    "        show_:bool=False):\n",
    "    \"\"\"\n",
    "    Overlays the border of a binary mask on a grayscale image and displays the result using matplotlib.\n",
    "\n",
    "    Args:\n",
    "    image (numpy.ndarray): Grayscale image.\n",
    "    mask (numpy.ndarray): Binary mask of the same size as the image.\n",
    "    border_color (tuple): RGB color for the mask border in the range [0, 1].\n",
    "    border_width (int): Width of the border.\n",
    "\n",
    "    Returns:\n",
    "    None: The function displays a plot.\n",
    "    \"\"\"\n",
    "    name_ = Path(im_path).name\n",
    "    gray_img = cv2.imread(f'{im_path}', cv2.IMREAD_GRAYSCALE)\n",
    "    if gray_img is None:\n",
    "        raise ValueError(\"Could not read the grayscale image\")\n",
    "\n",
    "    # Read the mask image\n",
    "    mask_img = cv2.imread(f'{msk_path}', cv2.IMREAD_GRAYSCALE)\n",
    "    mask_img = mask_img.astype(bool)\n",
    "    if mask_img is None:\n",
    "        raise ValueError(\"Could not read the mask image\")\n",
    "\n",
    "    # Check if dimensions of both images are the same\n",
    "    if gray_img.shape != mask_img.shape:\n",
    "        raise ValueError(\"Dimensions of grayscale image and mask do not match\")\n",
    "    # Ensure the mask is boolean\n",
    "\n",
    "    # Find the borders of the mask\n",
    "    dilated_mask = binary_dilation(mask_img, iterations=border_width)\n",
    "    eroded_mask = binary_erosion(mask_img, iterations=border_width)\n",
    "    border = dilated_mask & ~eroded_mask\n",
    "\n",
    "    # Convert grayscale image to RGB\n",
    "    rgb_image = np.stack([gray_img]*3, axis=-1) / \\\n",
    "        255.0  # Normalize for matplotlib\n",
    "\n",
    "    # Apply the colored border\n",
    "    rgb_image[border] = border_color\n",
    "    rgb_image = (rgb_image * 255).astype(np.uint8)\n",
    "\n",
    "    if new_img is not None:\n",
    "        new_img = np.concatenate([rgb_image, new_img], axis=1)\n",
    "        new_img = new_img.astype(np.uint8)\n",
    "        if save_new_img_path is not None:\n",
    "            cv2.imwrite(f'{save_new_img_path}/{name_}', new_img)\n",
    "        if show_:\n",
    "            fig, ax = plt.subplots(figsize=(scale_*new_img.shape[1] / dpi, scale_*new_img.shape[0] / dpi))\n",
    "            ax.imshow(new_img, cmap='gray')\n",
    "            ax.axis('off')  # Turn off axis numbers\n",
    "    else:\n",
    "        if show_:\n",
    "            fig, ax = plt.subplots(figsize=(scale_*rgb_image.shape[1] / dpi, scale_*rgb_image.shape[0] / dpi))\n",
    "            ax.imshow(rgb_image, cmap='gray')\n",
    "            ax.axis('off')  # Turn off axis numbers\n",
    "        if save_overlay_img_path is not None:\n",
    "            cv2.imwrite(f'{save_overlay_img_path}/{name_}', rgb_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def concat_images(\n",
    "        images:List[np.ndarray],\n",
    "        rows:int,  # number of rows\n",
    "        cols:int,  # number of columns in combined images\n",
    "        number:str # a text which will be inserted in the combined image\n",
    "        ):\n",
    "    'Concate images rows and cols and add a number to the image.'\n",
    "    targe_h = min([i.shape[0] for i in images])\n",
    "    target_w = min([i.shape[1] for i in images])\n",
    "    res_img = [cv2.resize(i, (target_w, targe_h)) for i in images]\n",
    "    res = []\n",
    "    for i in range(rows):\n",
    "        start_index = i * cols\n",
    "        end_index = start_index + cols\n",
    "        row_images = res_img[start_index:end_index]\n",
    "        row_concat = cv2.hconcat(row_images)\n",
    "        res.append(row_concat)\n",
    "    new_img = cv2.vconcat(res)\n",
    "    position = (6, 25)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale=0.6\n",
    "    color = (255, 0, 0)\n",
    "    im_n = cv2.putText(new_img, f'{number}', position, font, font_scale, color, 1, cv2.LINE_AA)\n",
    "    return im_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_poster_from_path(\n",
    "                mask_path:str, \n",
    "                im_path:str, # name of the image fodler , e.g. 'images' or 'X'\n",
    "                show_:str, # whether to show image, mask, poster\n",
    "                text:str,# text in image\n",
    "                scale=1\n",
    "                ):\n",
    "    'Show only masked part of the image or full image with mask'\n",
    "    row_col_dict = {35:(5, 7), 21:(3,7),30:(5,6), 34:(2,17), 22:(2,11), 36:(6,6), 20:(5, 4), 33:(3,11) }\n",
    "\n",
    "    # getting mask and iamge name from mask\n",
    "    name = Path(mask_path).name\n",
    "    im_name = Path(im_path)/name\n",
    "\n",
    "    msk_ = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "    img_ = cv2.imread(str(im_name), cv2.IMREAD_GRAYSCALE)\n",
    "    img_ = cv2.cvtColor(img_, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # finding contours and base on that concat only contours\n",
    "    contrs, _ = cv2.findContours(msk_, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    row, col = row_col_dict.get(len(contrs), (1,len(contrs)))\n",
    "    cv2.drawContours(img_, contrs, -1, (0, 255, 0), 1)\n",
    "    images_list = []\n",
    "    for c in contrs:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        offset = 25\n",
    "        new_img = img_[y-offset:y+h+offset, x-offset:x+w+offset]\n",
    "        images_list.append(new_img)\n",
    "    img_new = concat_images(images_list, row, col, number=text)\n",
    "\n",
    "\n",
    "    # show imagess\n",
    "    if show_ == 'both':\n",
    "        print(img_new.shape, img_.shape)\n",
    "        img_ = cv2.resize(img_, (img_new.shape[1], img_new.shape[0]))\n",
    "        new_img = cv2.hconcat([img_, img_new])\n",
    "        res = new_img.shape\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(scale * res[1]/dpi, scale*res[0]/dpi))\n",
    "        ax.imshow(new_img)\n",
    "\n",
    "    elif show_ == 'image':\n",
    "        res = img_.shape\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(scale * res[1]/dpi, scale*res[0]/dpi))\n",
    "        ax.imshow(img_)\n",
    "    else:\n",
    "        res = img_new.shape\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(scale * res[1]/dpi, scale*res[0]/dpi))\n",
    "        ax.imshow(img_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def get_template_part(\n",
    "    img:np.ndarray, #opencv image\n",
    "    tmp_img:np.ndarray # opencv image\n",
    "   ):\n",
    "   'Get bounding box coordinate from the image (x,y, w, h format)'\n",
    "\n",
    "   res = cv2.matchTemplate(\n",
    "                           img,\n",
    "                           tmp_img,\n",
    "                           cv2.TM_CCOEFF_NORMED\n",
    "   )\n",
    "\n",
    "   min_, max_, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "   top_left = max_loc\n",
    "   bottom_right = (top_left[0] + tmp_img.shape[1], top_left[1] + tmp_img.shape[0])\n",
    "\n",
    "   y = top_left[1]\n",
    "   h = bottom_right[1] - top_left[1]\n",
    "   x = top_left[0]\n",
    "   w = bottom_right[0] - top_left[0]\n",
    "   return x, y, w, h\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_image(\n",
    "        img:np.ndarray,\n",
    "        num_splits:int,\n",
    "        direction:str # horizontal or vertical\n",
    "        ):\n",
    "    'Split an image into different parts'\n",
    "\n",
    "    # Calculate the size of each split\n",
    "    if direction == 'horizontal':\n",
    "        split_size = img.shape[1] // num_splits\n",
    "    elif direction == 'vertical':\n",
    "        split_size = img.shape[0] // num_splits\n",
    "\n",
    "    # Split the image and store the parts in a list\n",
    "    parts = []\n",
    "    for i in range(num_splits):\n",
    "        if i == num_splits - 1:  # If this is the last split\n",
    "            if direction == 'horizontal':\n",
    "                part = img[:, i*split_size:]\n",
    "            elif direction == 'vertical':\n",
    "                part = img[i*split_size:, :]\n",
    "        else:\n",
    "            if direction == 'horizontal':\n",
    "                part = img[:, i*split_size:(i+1)*split_size]\n",
    "            elif direction == 'vertical':\n",
    "                part = img[i*split_size:(i+1)*split_size, :]\n",
    "        parts.append(part)\n",
    "\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_image_with_coordinates(img: np.ndarray, num_splits: int, direction: str) -> list:\n",
    "    indexed_parts_with_coords = []\n",
    "    split_size = img.shape[0] // num_splits if direction == 'vertical' else img.shape[1] // num_splits\n",
    "\n",
    "    for i in range(num_splits):\n",
    "        if direction == 'vertical':\n",
    "            start_y = i * split_size\n",
    "            end_y = img.shape[0] if i == num_splits - 1 else (i + 1) * split_size\n",
    "            part = img[start_y:end_y, :]\n",
    "            coordinates = (0, start_y, img.shape[1], end_y)\n",
    "        else:  # 'horizontal'\n",
    "            start_x = i * split_size\n",
    "            end_x = img.shape[1] if i == num_splits - 1 else (i + 1) * split_size\n",
    "            part = img[:, start_x:end_x]\n",
    "            coordinates = (start_x, 0, end_x, img.shape[0])\n",
    "        indexed_parts_with_coords.append((i, part, coordinates))\n",
    "\n",
    "    return indexed_parts_with_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_same_shape(\n",
    "        src_img:np.ndarray, # image which size needs to be replicated\n",
    "        dst_img:np.ndarray, # image which needs to resized\n",
    "    ):\n",
    "    'Create same shape of dst image like src_img'\n",
    "\n",
    "    h, w = src_img[:2]\n",
    "    add_h, add_w = dst_img[:2]\n",
    "\n",
    "    if h > add_h or w > add_w:\n",
    "        raise NotImplementedError('src_img should be smaller than dst_img')\n",
    "    else:\n",
    "        start_h, start_w = (add_h - h) // 2, (add_w - w) // 2\n",
    "        end_h, end_w = start_h + h, start_w + w\n",
    "        new = dst_img[start_h:end_h, start_w:end_w]\n",
    "        return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_contours_binary(\n",
    "    img:np.ndarray, # binary image \n",
    "    ):\n",
    "    'Return contours from the binary image'\n",
    "    cntrs, _= cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return cntrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def foo(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
