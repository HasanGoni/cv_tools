{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal tflex tool related scripts\n",
    "> Internal tflex tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_processing.tflex_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_tflex_commands(\n",
    "    input_folder: str,  # Path to folder containing files to process\n",
    "    python_script: str,  # Path to your Python script\n",
    "    output_file: str = \"tflex_commands.txt\",  # Name of tflex command file to create\n",
    "    file_pattern: str = \"*\",  # File pattern to match (e.g., \"*.txt\", \"*.csv\")\n",
    "    script_args: str = \"\",  # Additional arguments for your Python script\n",
    "    python_executable: str = \"python\"  # Python executable to use\n",
    "    )-> str: # Path to generated command file\n",
    "    \"\"\"\n",
    "    Generate tflex command file for parallel processing of files\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all files matching the pattern\n",
    "    search_path = Path(input_folder, file_pattern)\n",
    "    files = Path(search_path).ls()\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files found matching pattern: {search_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Generate commands\n",
    "    commands = []\n",
    "    for file_path in files:\n",
    "        # Create command for each file\n",
    "        cmd = f\"{python_executable} {python_script} {file_path}\"\n",
    "        if script_args:\n",
    "            cmd += f\" {script_args}\"\n",
    "        commands.append(cmd)\n",
    "    \n",
    "    # Write commands to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for cmd in commands:\n",
    "            f.write(cmd + '\\n')\n",
    "    \n",
    "    print(f\"Generated {len(commands)} commands in {output_file}\")\n",
    "    print(f\"Files to process: {len(files)}\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "# Alternative version for more complex scenarios\n",
    "def generate_tflex_commands_advanced(input_folder, python_script, output_file=\"tflex_commands.txt\",\n",
    "                                   file_extensions=None, recursive=True, \n",
    "                                   max_commands=None, script_template=None):\n",
    "    \"\"\"\n",
    "    Advanced version with more options\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Path to folder containing files\n",
    "        python_script (str): Path to your Python script\n",
    "        output_file (str): Name of tflex command file\n",
    "        file_extensions (list): List of file extensions to include ['.txt', '.csv']\n",
    "        recursive (bool): Search subfolders recursively\n",
    "        max_commands (int): Limit number of commands (for testing)\n",
    "        script_template (str): Custom command template with {file} placeholder\n",
    "    \"\"\"\n",
    "    \n",
    "    input_path = Path(input_folder)\n",
    "    files = []\n",
    "    \n",
    "    # Collect files based on extensions\n",
    "    if file_extensions:\n",
    "        for ext in file_extensions:\n",
    "            if recursive:\n",
    "                files.extend(input_path.rglob(f\"*{ext}\"))\n",
    "            else:\n",
    "                files.extend(input_path.glob(f\"*{ext}\"))\n",
    "    else:\n",
    "        # Get all files\n",
    "        if recursive:\n",
    "            files = [f for f in input_path.rglob(\"*\") if f.is_file()]\n",
    "        else:\n",
    "            files = [f for f in input_path.glob(\"*\") if f.is_file()]\n",
    "    \n",
    "    # Limit commands if specified\n",
    "    if max_commands and len(files) > max_commands:\n",
    "        files = files[:max_commands]\n",
    "        print(f\"Limited to first {max_commands} files\")\n",
    "    \n",
    "    # Generate commands\n",
    "    commands = []\n",
    "    for file_path in files:\n",
    "        if script_template:\n",
    "            # Use custom template\n",
    "            cmd = script_template.format(file=str(file_path))\n",
    "        else:\n",
    "            # Default template\n",
    "            cmd = f\"python3 {python_script} {file_path}\"\n",
    "        commands.append(cmd)\n",
    "    \n",
    "    # Write to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for cmd in commands:\n",
    "            f.write(cmd + '\\n')\n",
    "    \n",
    "    print(f\"Generated {len(commands)} commands in {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "# Example usage functions\n",
    "def create_data_processing_commands(data_folder, processing_script):\n",
    "    \"\"\"Example for data processing workflow\"\"\"\n",
    "    return generate_tflex_commands(\n",
    "        input_folder=data_folder,\n",
    "        python_script=processing_script,\n",
    "        output_file=\"process_data_commands.txt\",\n",
    "        file_pattern=\"*.csv\",\n",
    "        script_args=\"--output-dir ./results\"\n",
    "    )\n",
    "\n",
    "def create_image_processing_commands(image_folder, processing_script):\n",
    "    \"\"\"Example for image processing workflow\"\"\"\n",
    "    return generate_tflex_commands_advanced(\n",
    "        input_folder=image_folder,\n",
    "        python_script=processing_script,\n",
    "        output_file=\"process_images_commands.txt\",\n",
    "        file_extensions=['.jpg', '.png', '.tiff'],\n",
    "        recursive=True,\n",
    "        script_template=\"python3 {script} --input {file} --output ./processed/\"\n",
    "    )\n",
    "\n",
    "# Main workflow function\n",
    "def run_tflex_workflow(input_folder, python_script, tflex_executable=\"tflex\"):\n",
    "    \"\"\"\n",
    "    Complete workflow: generate commands and run tflex\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Folder with files to process\n",
    "        python_script (str): Your Python processing script\n",
    "        tflex_executable (str): Path to tflex executable\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate command file\n",
    "    cmd_file = generate_tflex_commands(input_folder, python_script)\n",
    "    \n",
    "    if cmd_file:\n",
    "        # Run tflex (you'll need to adjust this based on tflex syntax)\n",
    "        tflex_cmd = f\"{tflex_executable} {cmd_file}\"\n",
    "        print(f\"Run this command: {tflex_cmd}\")\n",
    "        \n",
    "        # Optionally execute automatically\n",
    "        # import subprocess\n",
    "        # result = subprocess.run(tflex_cmd, shell=True, capture_output=True, text=True)\n",
    "        # print(result.stdout)\n",
    "        \n",
    "        return tflex_cmd\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db314dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52746a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ===============================================================================\n",
    "# ORIGINAL FUNCTION - Process each file individually\n",
    "# ===============================================================================\n",
    "\n",
    "def generate_tflex_commands(\n",
    "    input_folder,  # Path to folder containing files to process\n",
    "    python_script,  # Path to your Python script\n",
    "    output_file: str = \"tflex_commands.txt\",  # Name of tflex command file to create\n",
    "    file_pattern: str = \"*\",  # File pattern to match (e.g., \"*.txt\", \"*.csv\")\n",
    "    script_args: str = \"\",  # Additional arguments for your Python script\n",
    "    python_executable: str = \"python3\"  # Python executable to use\n",
    "    ):\n",
    "    \"\"\"\n",
    "    ORIGINAL: Generate tflex command file for parallel processing of individual files\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to generated command file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all files matching the pattern\n",
    "    search_path = os.path.join(input_folder, file_pattern)\n",
    "    files = glob.glob(search_path)\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files found matching pattern: {search_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Generate commands - ONE COMMAND PER FILE\n",
    "    commands = []\n",
    "    for file_path in files:\n",
    "        cmd = f\"{python_executable} {python_script} {file_path}\"\n",
    "        if script_args:\n",
    "            cmd += f\" {script_args}\"\n",
    "        commands.append(cmd)\n",
    "    \n",
    "    # Write commands to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for cmd in commands:\n",
    "            f.write(cmd + '\\n')\n",
    "    \n",
    "    print(f\"Generated {len(commands)} individual file commands in {output_file}\")\n",
    "    print(f\"Files to process: {len(files)}\")\n",
    "    \n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7268547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ===============================================================================\n",
    "# NEW FUNCTION - Process files in batches\n",
    "# ===============================================================================\n",
    "\n",
    "def generate_batch_tflex_commands(\n",
    "    input_folder,  # Path to folder containing files to process\n",
    "    python_script,  # Path to your Python batch processing script\n",
    "    files_per_batch: int = 50,  # Number of files to process per batch/job\n",
    "    output_file: str = \"batch_tflex_commands.txt\",  # Name of tflex command file to create\n",
    "    file_pattern: str = \"*\",  # File pattern to match (e.g., \"*.txt\", \"*.csv\")\n",
    "    file_extensions: list = None,  # List of file extensions ['.txt', '.csv', '.jpg']\n",
    "    script_args: str = \"\",  # Additional arguments for your Python script\n",
    "    python_executable: str = \"python3\",  # Python executable to use\n",
    "    recursive: bool = True,  # Search subfolders recursively\n",
    "    batch_dir: str = \"batches\"\n",
    "    )-> dict: # Information about generated batches and commands\n",
    "    \"\"\"\n",
    "    NEW: Generate tflex commands for batch processing - each command processes multiple files\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    input_path = Path(input_folder)\n",
    "    files = []\n",
    "    \n",
    "    # Collect files based on pattern or extensions\n",
    "    if file_extensions:\n",
    "        # Use specific extensions\n",
    "        for ext in file_extensions:\n",
    "            if recursive:\n",
    "                files.extend(input_path.rglob(f\"*{ext}\"))\n",
    "                files.extend(input_path.rglob(f\"*{ext.upper()}\"))\n",
    "            else:\n",
    "                files.extend(input_path.glob(f\"*{ext}\"))\n",
    "                files.extend(input_path.glob(f\"*{ext.upper()}\"))\n",
    "    else:\n",
    "        # Use file pattern\n",
    "        if recursive:\n",
    "            files.extend(input_path.rglob(file_pattern))\n",
    "        else:\n",
    "            files.extend(input_path.glob(file_pattern))\n",
    "    \n",
    "    # Convert to strings\n",
    "    files = [str(f) for f in files if Path(f).is_file()]\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files found in {input_folder}\")\n",
    "        return None\n",
    "    \n",
    "    # Create batches\n",
    "    batches = []\n",
    "    for i in range(0, len(files), files_per_batch):\n",
    "        batch = files[i:i + files_per_batch]\n",
    "        batches.append(batch)\n",
    "    \n",
    "    print(f\"Found {len(files)} files\")\n",
    "    print(f\"Created {len(batches)} batches of ~{files_per_batch} files each\")\n",
    "    \n",
    "    # Create batch directory\n",
    "    os.makedirs(batch_dir, exist_ok=True)\n",
    "    \n",
    "    # Create batch files and commands\n",
    "    commands = []\n",
    "    batch_info = []\n",
    "    \n",
    "    for batch_idx, batch in enumerate(batches):\n",
    "        # Create batch file (list of files for this batch)\n",
    "        batch_filename = f\"batch_{batch_idx:04d}.txt\"\n",
    "        batch_filepath = os.path.join(batch_dir, batch_filename)\n",
    "        \n",
    "        with open(batch_filepath, 'w') as f:\n",
    "            for file_path in batch:\n",
    "                f.write(file_path + '\\n')\n",
    "        \n",
    "        # Create tflex command for this batch\n",
    "        cmd = f\"{python_executable} {python_script} --batch-file {batch_filepath}\"\n",
    "        if script_args:\n",
    "            cmd += f\" {script_args}\"\n",
    "        \n",
    "        commands.append(cmd)\n",
    "        batch_info.append({\n",
    "            'batch_id': batch_idx,\n",
    "            'batch_file': batch_filepath,\n",
    "            'file_count': len(batch),\n",
    "            'files': batch\n",
    "        })\n",
    "    \n",
    "    # Write commands to tflex file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for cmd in commands:\n",
    "            f.write(cmd + '\\n')\n",
    "    \n",
    "    # Save batch information\n",
    "    batch_info_file = os.path.join(batch_dir, \"batch_info.json\")\n",
    "    with open(batch_info_file, 'w') as f:\n",
    "        json.dump(batch_info, f, indent=2)\n",
    "    \n",
    "    result = {\n",
    "        'command_file': output_file,\n",
    "        'total_files': len(files),\n",
    "        'total_batches': len(batches),\n",
    "        'files_per_batch': files_per_batch,\n",
    "        'batch_directory': batch_dir,\n",
    "        'batch_info_file': batch_info_file,\n",
    "        'batches': batch_info\n",
    "    }\n",
    "    \n",
    "    print(f\"Generated {len(commands)} batch commands in {output_file}\")\n",
    "    print(f\"Batch files saved in: {batch_dir}\")\n",
    "    print(f\"Batch info saved in: {batch_info_file}\")\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c30fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ===============================================================================\n",
    "# UTILITY FUNCTIONS FOR BATCH PROCESSING\n",
    "# ===============================================================================\n",
    "\n",
    "def generate_image_batch_commands(\n",
    "    image_folder,  # Folder containing images\n",
    "    processing_script,  # Your image processing script\n",
    "    images_per_batch: int = 100,  # Images per tflex job\n",
    "    output_dir: str = \"./results\",  # Output directory\n",
    "    batch_size: int = 8,  # Batch size for your script's internal processing\n",
    "    num_processes: int = 4  # Number of processes for multiprocessing\n",
    "):\n",
    "    \"\"\"\n",
    "    Specialized function for image processing with batches\n",
    "    \"\"\"\n",
    "    \n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif']\n",
    "    \n",
    "    script_args = f\"--output-dir {output_dir} --batch-size {batch_size} --num-processes {num_processes}\"\n",
    "    \n",
    "    return generate_batch_tflex_commands(\n",
    "        input_folder=image_folder,\n",
    "        python_script=processing_script,\n",
    "        files_per_batch=images_per_batch,\n",
    "        file_extensions=image_extensions,\n",
    "        script_args=script_args,\n",
    "        output_file=\"image_batch_commands.txt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ff73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_data_batch_commands(\n",
    "    data_folder,  # Folder containing data files\n",
    "    processing_script,  # Your data processing script\n",
    "    files_per_batch: int = 20,  # Files per tflex job\n",
    "    output_dir: str = \"./processed_data\",  # Output directory\n",
    "    num_processes: int = 8  # Number of processes for multiprocessing\n",
    "):\n",
    "    \"\"\"\n",
    "    Specialized function for data file processing with batches\n",
    "    \"\"\"\n",
    "    \n",
    "    data_extensions = ['.csv', '.json', '.txt', '.tsv', '.xlsx']\n",
    "    \n",
    "    script_args = f\"--output-dir {output_dir} --num-processes {num_processes}\"\n",
    "    \n",
    "    return generate_batch_tflex_commands(\n",
    "        input_folder=data_folder,\n",
    "        python_script=processing_script,\n",
    "        files_per_batch=files_per_batch,\n",
    "        file_extensions=data_extensions,\n",
    "        script_args=script_args,\n",
    "        output_file=\"data_batch_commands.txt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184131a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ===============================================================================\n",
    "# EXAMPLE BATCH PROCESSING SCRIPT TEMPLATE\n",
    "# ===============================================================================\n",
    "\n",
    "def create_batch_processing_template(\n",
    "    template_file=\"batch_processor_template.py\"):\n",
    "    \"\"\"\n",
    "    Create a template for batch processing script that works with the generated commands\n",
    "    \"\"\"\n",
    "    \n",
    "    template_code = '''import argparse\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def process_single_file(file_path, output_dir, **kwargs):\n",
    "    \"\"\"\n",
    "    Process a single file - CUSTOMIZE THIS FUNCTION\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to file to process\n",
    "        output_dir (str): Output directory\n",
    "        **kwargs: Additional arguments\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Processing: {file_path}\")\n",
    "    \n",
    "    # YOUR PROCESSING CODE HERE\n",
    "    # Example:\n",
    "    # - Load file\n",
    "    # - Process data/image\n",
    "    # - Save results\n",
    "    \n",
    "    # Example output filename\n",
    "    input_name = Path(file_path).stem\n",
    "    output_path = os.path.join(output_dir, f\"{input_name}_processed.txt\")\n",
    "    \n",
    "    # Simulate processing\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(f\"Processed: {file_path}\\\\n\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def process_file_batch(file_paths, output_dir, num_processes=4, **kwargs):\n",
    "    \"\"\"\n",
    "    Process a batch of files using multiprocessing\n",
    "    \n",
    "    Args:\n",
    "        file_paths (list): List of file paths to process\n",
    "        output_dir (str): Output directory\n",
    "        num_processes (int): Number of processes to use\n",
    "        **kwargs: Additional arguments passed to process_single_file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Processing {len(file_paths)} files with {num_processes} processes\")\n",
    "    \n",
    "    # Prepare arguments for multiprocessing\n",
    "    args_list = [(fp, output_dir) for fp in file_paths]\n",
    "    \n",
    "    # Process files in parallel\n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        results = pool.starmap(process_single_file, args_list)\n",
    "    \n",
    "    successful = sum(1 for r in results if r is not None)\n",
    "    print(f\"Successfully processed {successful}/{len(file_paths)} files\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Batch file processor')\n",
    "    parser.add_argument('--batch-file', required=True, \n",
    "                       help='File containing list of files to process')\n",
    "    parser.add_argument('--output-dir', required=True, \n",
    "                       help='Output directory')\n",
    "    parser.add_argument('--num-processes', type=int, default=4,\n",
    "                       help='Number of processes for multiprocessing')\n",
    "    parser.add_argument('--batch-size', type=int, default=1,\n",
    "                       help='Batch size (if needed for your processing)')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Read batch file\n",
    "    with open(args.batch_file, 'r') as f:\n",
    "        file_paths = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    if not file_paths:\n",
    "        print(\"No files found in batch file\")\n",
    "        return\n",
    "    \n",
    "    # Process the batch\n",
    "    results = process_file_batch(\n",
    "        file_paths=file_paths,\n",
    "        output_dir=args.output_dir,\n",
    "        num_processes=args.num_processes\n",
    "    )\n",
    "    \n",
    "    print(f\"Batch processing completed: {args.batch_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "    \n",
    "    with open(template_file, 'w') as f:\n",
    "        f.write(template_code)\n",
    "    \n",
    "    print(f\"Created batch processing template: {template_file}\")\n",
    "    print(\"Customize the process_single_file() function for your needs\")\n",
    "    \n",
    "    return template_file\n",
    "\n",
    "# ===============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ===============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Individual file processing (original method)\n",
    "    print(\"=== Original Method: Individual Files ===\")\n",
    "    generate_tflex_commands(\n",
    "        input_folder=\"/path/to/data\",\n",
    "        python_script=\"process_single_file.py\",\n",
    "        file_pattern=\"*.txt\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
    "    \n",
    "    # Example 2: Batch processing (new method)\n",
    "    print(\"=== New Method: Batch Processing ===\")\n",
    "    batch_result = generate_batch_tflex_commands(\n",
    "        input_folder=\"/path/to/data\", \n",
    "        python_script=\"process_batch.py\",\n",
    "        files_per_batch=50,\n",
    "        file_extensions=['.txt', '.csv', '.json'],\n",
    "        script_args=\"--output-dir ./results --num-processes 8\"\n",
    "    )\n",
    "    \n",
    "    if batch_result:\n",
    "        print(f\"\\\\nBatch processing setup complete!\")\n",
    "        print(f\"Run: tflex {batch_result['command_file']}\")\n",
    "        print(f\"Total batches: {batch_result['total_batches']}\")\n",
    "        print(f\"Files per batch: ~{batch_result['files_per_batch']}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
    "    \n",
    "    # Example 3: Create template for batch processor\n",
    "    print(\"=== Creating Batch Processor Template ===\")\n",
    "    create_batch_processing_template()\n",
    "    \n",
    "    # Example 4: Specialized image processing\n",
    "    print(\"\\\\n=== Image Processing Example ===\")\n",
    "    image_result = generate_image_batch_commands(\n",
    "        image_folder=\"/path/to/images\",\n",
    "        processing_script=\"image_batch_processor.py\",\n",
    "        images_per_batch=100,\n",
    "        num_processes=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export('11_data_processing.tflex_tools.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48306037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
