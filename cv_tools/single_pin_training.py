# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/28_single_pin_training.ipynb.

# %% auto 0
__all__ = ['pooling', 'conv_block', 'encoder_small', 'decoder_small', 'encoder_decoder_small_block', 'create_dataset', 'process_',
           'read_normalize_and_resize', 'normalize', 'read_and_binarize_mask', 'process_image_and_mask',
           'augmentation_', 'augment_data', 'CombinedLoss', 'training_model', 'create_parser',
           'create_config_from_args', 'get_pretrained_model', 'get_model', 'main']

# %% ../nbs/28_single_pin_training.ipynb 4
from typing import Dict
import tensorflow as tf
from fastcore.all import *
from datetime import datetime
from tensorflow.keras import backend as K
from pathlib import Path
import tensorflow as tf
from collections import Counter
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from pathlib import Path
from functools import partial
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
import os
import albumentations as A
import random
import cv2
import argparse
from fastcore.basics import patch
from datetime import datetime
from fastcore.all import *
# from fastai.vision.all import *
from dataclasses import dataclass, field
import tensorflow_addons as tfa
from typing import Union, List, Tuple, Optional, Callable, Dict, Any
from omegaconf import OmegaConf
from pathlib import Path
import pandas as pd
import numpy as np
import shutil
from tqdm.notebook import tqdm
import cv2
from fastcore.all import *
from ai_vision_tool.model_creation import *
import requests
from urllib3.exceptions import InsecureRequestWarning
import math

# %% ../nbs/28_single_pin_training.ipynb 5


def pooling(
        inputs,
        max_pool_only=False,
        both=True,
        pool_size=2):
    if both:
        p1 = tf.keras.layers.MaxPooling2D(
            (pool_size, pool_size))(inputs)
        p2 = tf.keras.layers.AvgPool2D(
            pool_size=(pool_size, pool_size))(inputs)
        return tf.keras.layers.concatenate([p1, p2])
    elif max_pool_only:
        return tf.keras.layers.MaxPooling2D(
            (pool_size, pool_size))(inputs)
    else:
        return tf.keras.layers.AvgPool2D(
            pool_size=(pool_size, pool_size))(inputs)


# %% ../nbs/28_single_pin_training.ipynb 6
def conv_block(inputs, filter_no, kernel_size, batch_nm=True, dropout=True, drp_rt=0.1):
    c1 = tf.keras.layers.Conv2D(
        filter_no,
        (kernel_size, kernel_size),

        kernel_initializer='he_normal',
        padding='same',
        activation=None)(inputs)
    if batch_nm:
        c1 = tf.keras.layers.BatchNormalization()(c1)
    c1 = tf.keras.layers.Activation('relu')(c1)
    if dropout:
        c1 = tf.keras.layers.Dropout(drp_rt)(c1)
    return c1

# %% ../nbs/28_single_pin_training.ipynb 7


def encoder_small(input_size):
    ' Create encoder layer'

    inputs = tf.keras.layers.Input(input_size)
    s = inputs
    c1 = conv_block(
        inputs=s,
        filter_no=4,
        kernel_size=3,
        batch_nm=True,
        dropout=True,
        drp_rt=0.2
    )

    c1 = conv_block(
        inputs=c1,
        filter_no=4,
        kernel_size=3,
        batch_nm=True,
        dropout=True,
        drp_rt=0.2
    )
    p1 = pooling(inputs=c1, both=True, pool_size=2)

    c2 = conv_block(
        inputs=p1,
        filter_no=8,
        kernel_size=3,
        batch_nm=True,
        dropout=True,
        drp_rt=0.2)

    c2 = conv_block(
        inputs=c2,
        filter_no=8,
        kernel_size=3,
        batch_nm=True,
        dropout=False,
        drp_rt=0.2  # will not be used
    )

    p2 = pooling(inputs=c2, both=True, pool_size=2)

    c3 = conv_block(
        inputs=p2,
        filter_no=16,
        kernel_size=3,

        dropout=True,
        drp_rt=0.2)

    c3 = conv_block(
        inputs=c3,
        filter_no=16,
        kernel_size=3,
        dropout=False,
        drp_rt=0.2  # will not be used
    )
    p3 = pooling(inputs=c3, both=True, pool_size=2)

    c4 = conv_block(
        inputs=p3,
        filter_no=32,
        batch_nm=True,
        kernel_size=3,
        dropout=True,
        drp_rt=0.2
    )
    c4 = conv_block(
        inputs=c4,
        filter_no=32,
        kernel_size=3,
        batch_nm=True,
        dropout=False,
        drp_rt=0.2  # will not be used
    )
    return s, c1, c2, c3, c4


# %% ../nbs/28_single_pin_training.ipynb 8
def decoder_small(c1, c2, c3, c4):

    # one concat block
    u5 = tf.keras.layers.Conv2DTranspose(
        16,
        (2, 2),
        strides=(2, 2),
        padding='same')(c4)
    u5 = tf.keras.layers.concatenate([u5, c3])

    c5 = conv_block(
        inputs=u5,
        filter_no=16,
        kernel_size=3,
        batch_nm=True,
        dropout=True,
        drp_rt=0.2)

    c5 = conv_block(
        inputs=c5,
        filter_no=16,
        kernel_size=3,
        batch_nm=True,
        dropout=False,
        drp_rt=0.2,  # will not be used
    )

    # second concat block
    u6 = tf.keras.layers.Conv2DTranspose(
        8,
        (2, 2),
        strides=(2, 2),
        padding='same')(c5)

    u6 = tf.keras.layers.concatenate([u6, c2])
    c6 = conv_block(
        inputs=u6,
        filter_no=8,
        kernel_size=3,
        batch_nm=True,
        dropout=True,
        drp_rt=0.2)
    c6 = conv_block(
        inputs=c6,
        filter_no=8,
        kernel_size=3,
        batch_nm=True,
        dropout=False,
        drp_rt=0)

    # third conccat layer
    u6 = tf.keras.layers.Conv2DTranspose(
        4, (2, 2), strides=(2, 2), padding='same')(c6)
    u6 = tf.keras.layers.concatenate([u6, c1])
    c7 = conv_block(
        inputs=u6,
        filter_no=4,
        kernel_size=3,
        batch_nm=True,
        dropout=True,
        drp_rt=0.2)
    c8 = conv_block(
        inputs=c7,
        filter_no=4,
        kernel_size=3,
        batch_nm=True,
        dropout=False,
        drp_rt=0.2)
    return c8

# %% ../nbs/28_single_pin_training.ipynb 12


def encoder_decoder_small_block(
    input_size: Tuple[int],
    n_classes: int = 2
):
    'Create Encoder block'
    s, c1, c2, c3, c4 = encoder_small(input_size)

    c8 = decoder_small(c1, c2, c3, c4)
    outputs = tf.keras.layers.Conv2D(
        n_classes,
        (1, 1),
        activation='sigmoid',

    )(c8)
    return tf.keras.models.Model(inputs=s, outputs=outputs)


# %% ../nbs/28_single_pin_training.ipynb 18
def create_dataset(config, training=True):
    def get_data(config, training):

        mask_names = [i.name for i in Path(
            config['label_path']).ls(file_exts='.png')]
        print(f"{'#'*10}")
        print(f' number of masks found {len(mask_names)}')
        images = sorted([str(i)for i in Path(config['image_path']).ls(
            file_exts='.png') if Path(i).name in mask_names])
        image_names = [Path(i).name for i in images]
        masks = sorted([str(i)for i in Path(config['label_path']).ls(
            file_exts='.png') if Path(i).name in image_names])
        print(f' number of images found {len(masks)}')

        train_images, test_images, \
            train_labels, test_labels = train_test_split(
                images,
                masks,
                test_size=config['test_size'],
                random_state=42)

        if training:

            return train_images, train_labels
        else:
            return test_images, test_labels
    images, masks = get_data(config, training=training)

    dataset = tf.data.Dataset.from_tensor_slices(
                                                (images, masks)
    )
    # if training:
    # dataset = dataset.map(lambda x, y: (x, y, tf.py_function(repeat_image, [x], [tf.int64])))
    # dataset = dataset.flat_map(lambda x, y, n: tf.data.Dataset.from_tensors((x, y)).repeat(n[0]))

    dataset = dataset.map(
        partial(process_, cfg=config),
        num_parallel_calls=tf.data.experimental.AUTOTUNE
    )
    if training:
        dataset = dataset.map(partial(
            augment_data,
            im_height=config['IMAGE_HEIGHT'],
            im_width=config['IMAGE_WIDTH'], config=config),
            num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(
            tf.data.experimental.AUTOTUNE)

        dataset = dataset.shuffle(buffer_size=2)
    dataset = dataset.repeat()

    print(f" number of batches found {'#'*10}")
    print(f'config[bs] =  {config["bs"]}')
    dataset = dataset.batch(config['bs'])
    # if training:
    # dataset = dataset.map(lambda x, y: mixup(x, y, alpha=0.2))
    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    return dataset

# %% ../nbs/28_single_pin_training.ipynb 19


def process_(image_path, mask_path, cfg):
    image, mask = process_image_and_mask(
        image_path,
        mask_path,
        cfg
    )
    return image, mask

# %% ../nbs/28_single_pin_training.ipynb 22


def read_normalize_and_resize(
    im_file,
    cfg,
):
    im = tf.io.read_file(im_file)
    im = tf.image.decode_png(im, channels=cfg['channel_number'])

    im = tf.cast(tf.image.resize(im,
                                 [cfg['IMAGE_HEIGHT'], cfg['IMAGE_WIDTH']],
                                 method=tf.image.ResizeMethod.BILINEAR, antialias=False), tf.float32)
    im = normalize(im, cfg['min'])

    return im


# %% ../nbs/28_single_pin_training.ipynb 23
def normalize(
    image,  # :Union[np.ndarray, tf.Tensor],
        min=0):
    ' Normlaize image'
    def _normalize(im):
        img = tf.cast(im, tf.float32)
        return img / 255.0

    if min == 0:
        return _normalize(image)
    else:
        return (_normalize(image) * 2.0) - 1.0

# %% ../nbs/28_single_pin_training.ipynb 24


def read_and_binarize_mask(
    mask_file,
    cfg,
):
    'Read and binarize masks'
    mask = tf.io.read_file(mask_file)
    mask = tf.image.decode_png(
        mask,
        channels=cfg['channel_number'])
    mask = tf.image.resize(
        mask,
        (cfg['IMAGE_HEIGHT'], cfg['IMAGE_WIDTH']),
        antialias=True
    )
    mask = tf.cast(mask > 127, tf.float32)

    return mask


# %% ../nbs/28_single_pin_training.ipynb 25
def process_image_and_mask(
        image_path,
        mask_path,
        cfg):
    'Process both image masks'
    image = read_normalize_and_resize(

        image_path,
        cfg)
    mask = read_and_binarize_mask(
        mask_path,
        cfg)
    return image, mask

# %% ../nbs/28_single_pin_training.ipynb 30


def augmentation_(

    im_height: int,
    im_width: int,
    image: tf.Tensor,
    mask: tf.Tensor,
):

    scale = (0.8, 1.0)
    ratio = (1.0, 1.0)
    aug = A.Compose([
                    A.OneOf([
                        A.ShiftScaleRotate(
                            shift_limit=0.04,
                            scale_limit=0.04,
                            rotate_limit=12,
                            border_mode=cv2.BORDER_CONSTANT,
                            p=0.8),
                        A.ShiftScaleRotate(
                            shift_limit=0.14,
                            scale_limit=0.04,
                            rotate_limit=20,
                            border_mode=cv2.BORDER_CONSTANT,
                            p=0.1)
                    ], p=0.8),
                    A.OneOf([A.ShiftScaleRotate(
                        shift_limit=0.3,
                        scale_limit=0,
                        rotate_limit=0,
                        p=0.5
                    ),
                        A.ShiftScaleRotate(
                        shift_limit=-0.3,
                        scale_limit=0,
                        rotate_limit=0,
                        p=0.5
                    )]),
                    A.HorizontalFlip(p=0.5),
                    A.VerticalFlip(p=0.5),
                    # A.RandomRotate90(p=0.5),
                    A.Transpose(p=0.5),
                    A.RandomBrightnessContrast(p=0.5),
                    # A.RandomContrast(p=0.5, limit=(-0.5, 0.5)),
                    A.ColorJitter(brightness=0.1, p=0.02),
                    # A.Salt(p=0.2, per_channel=True),
                    # A.GaussNoise(var_limit=(10, 50), mean=0, p=0.5),
                    A.GaussNoise(var_limit=(0.01, 0.05), mean=0, p=0.5),
                    A.GaussianBlur(blur_limit=(3, 7), p=0.5),
                    A.MultiplicativeNoise(multiplier=(0.05, 0.19),
                                          per_channel=False, p=0.5),
                    ])

    aug_data = aug(image=image, mask=mask)
    image, mask = aug_data['image'], aug_data['mask']
    return image, mask

# %% ../nbs/28_single_pin_training.ipynb 31


def augment_data(image, mask, im_height, im_width, config):

    image_shape = (im_height, im_width, 1)
    aug_img, aug_mask = tf.numpy_function(
        func=augmentation_,
        inp=[
            im_height,
            im_width,
            image,
            mask], Tout=(tf.float32, tf.float32))
    aug_img.set_shape(image_shape)
    aug_mask.set_shape(image_shape)
    aug_img = tf.image.resize(
        aug_img, [config['IMAGE_HEIGHT'], config['IMAGE_WIDTH']])
    aug_mask = tf.image.resize(
        aug_mask, [config['IMAGE_HEIGHT'], config['IMAGE_WIDTH']])
    aug_mask = tf.cast(aug_mask > 0.5, tf.float32)
    return aug_img, aug_mask

# %% ../nbs/28_single_pin_training.ipynb 34


class CombinedLoss(
    tf.keras.losses.Loss
):
    'Focal + Dice losss together'

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.smooth = 100
        self.focal_loss = tf.keras.losses.BinaryFocalCrossentropy(
            gamma=2,
            from_logits=False)

    def dice_loss(self, y_true, y_pred):
        y_true_f = K.flatten(y_true)
        y_pred_f = K.flatten(y_pred)
        intersection = K.sum(y_true_f * y_pred_f)
        dice = (2. * intersection + self.smooth) / \
            (K.sum(y_true_f) + K.sum(y_pred_f) + self.smooth)
        return 1 - dice

    def call(self, y_true, y_pred):
        fl = self.focal_loss(y_true, y_pred)
        dl = self.dice_loss(y_true, y_pred)
        return fl + dl


# %% ../nbs/28_single_pin_training.ipynb 40
def training_model(
    config: Dict,
    model: tf.keras.models.Model,
):

    train_ds = create_dataset(config, training=True)
    test_ds = create_dataset(config, training=False)

    LR_START = config['start_learning_rate']
    LR_MAX = config['max_learning_rate']
    LR_MIN = config['min_learning_rate']
    LR_RAMPUP_EPOCHS = config['rampup_epochs']
    LR_SUSTAIN_EPOCHS = config['sustain_epochs']

    current_datetime = datetime.now()
    time = current_datetime.strftime("%H_%M_%S")

    epochs = config['EPOCHS']

    def lrfn(epochs):
        if epochs < LR_RAMPUP_EPOCHS:
            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epochs + LR_START
        elif epochs < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:
            lr = LR_MAX
        else:
            decay_total_epochs = epochs - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1
            decay_epoch_index = epochs - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS
            phase = math.pi * decay_epoch_index / \
                (decay_total_epochs + 0.00000001)
            cosine_decay = 0.5 * (1 + math.cos(phase))
            lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN
        return lr

    lr_callback = tf.keras.callbacks.LearningRateScheduler(
        lrfn,
        verbose=True
    )
    optimizer = tfa.optimizers.AdamW(
        learning_rate=1e-3,
        weight_decay=1e-5,
        clipnorm=1.0)

    loss = CombinedLoss()
    metrics = [tf.keras.metrics.BinaryIoU(name='foreground',
                                          target_class_ids=[1],
                                          threshold=0.5),
               tf.keras.metrics.FalsePositives()]
    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
        filepath=f"{config['model_save_path']}/time_{time}_val_frGrnd" +
        '{val_foreground:.4f}_epoch_{epoch}.h5',
        monitor='val_foreground', verbose=1, save_best_only=False, save_freq='epoch')

    model.compile(
        loss=loss,
        metrics=metrics,
        optimizer=optimizer
    )
    callbacks = [
        lr_callback,
        model_checkpoint
    ]

    his = model.fit(
        train_ds,
        validation_data=test_ds,
        epochs=epochs if epochs else config['EPOCHS'],
        steps_per_epoch=config['steps_per_epoch'],
        validation_steps=config['validation_steps'],
        callbacks=callbacks
    )
    return his


# %% ../nbs/28_single_pin_training.ipynb 51
def create_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '-imn',
        '--initial_model_name',
        type=str,
        help='current loaded model name'
    )
    parser.add_argument(
        '-en',
        '--epoch_number',
        type=int,
        default=200,
        help='Number of epochs for training'
    )
    parser.add_argument(
        '-ptr',
        '--pretrained',
        action='store_true',
        help='whether pretrained model is used or from scratch training'
    )
    parser.add_argument(
        '-imp',
        '--initial_model_path',
        type=str,
        help='current loaded model path'
    )

    parser.add_argument(
        '-mp',
        '--model_path',
        type=str,
        default='/home/ai_easypid/data/projects/easy_pin_detection/models1024_1224/gamma2',
        help='saved model path '
    )

    parser.add_argument(
        '-tln',
        '--trn_layer_num',
        default=42,
        type=int,
        help='whether to train full network or only a part'

    )

    parser.add_argument(
        '-mn',
        '--model_name',
        type=str,
        default='higer_learning',
        help='experiment description')

    parser.add_argument(
        '-ip',
        '--image_path',
        type=str,
        default='/home/ai_easypid/data/projects/easy_pin_detection/ali1_new_download/images',
        help='name of image path')

    parser.add_argument(
        '-mpt',
        '--mask_path',
        type=str,
        default='/home/ai_easypid/data/projects/easy_pin_detection/ali1_new_download/masks',
        help='name of mask path')
    parser.add_argument(
        '-bs',
        '--batch_size',
        type=int,
        default=3,
        help='batch size')

    parser.add_argument(
        '-ih',
        '--image_height',
        type=int,
        default=256,
        help='height of image resolution ')

    parser.add_argument(
        '-iw',
        '--image_width',
        type=int,
        default=1632,
        help='width of image resolution ')

    parser.add_argument(
        '-sl',
        '--start_learning_rate',
        help='start learning rate during training',
        type=float,
        default=0.002,
    )
    parser.add_argument(
        '-ml',
        '--max_learning_rate',
        help='maximum learning rate during training',
        type=float,
        default=0.02,
    )
    parser.add_argument(
        '-mnl',
        '--minimum_learning_rate',
        type=float,
        default=2e-5,
        help='minimum learning rate during training'
    )

    parser.add_argument(
        '-re',
        '--rampup_epochs',
        default=8,
        help='rampup epoch number'
    )

    parser.add_argument(
        '-se',
        '--sustain_epochs',
        default=5,
        help='epoch needed to sustain after achieving maximum learning rate',
    )

    args = parser.parse_args()
    return args

# %% ../nbs/28_single_pin_training.ipynb 52


def create_config_from_args(args):
    args = create_parser()
    print(args)
    config = {}
    config = {}
    config['image_path'] = args.image_path
    config['label_path'] = args.mask_path
    config['class_names'] = ['Pin']
    config['test_size'] = 0.2
    config['train_count'] = int(
        len(Path(config['image_path']).ls()) * (1 - config['test_size']))
    print(f"{'#'*50} train_count == {config['train_count']}")
    # 5055 - config['train_count']
    config['test_count'] = int(len(Path(config['image_path']).ls())*0.2)
    config['num_classes'] = 1
    config['IMAGE_HEIGHT'] = int(args.image_height)
    config['IMAGE_WIDTH'] = int(args.image_width)
    config['channel_number'] = 1
    config['one_channel'] = True
    config['im_size'] = (config['IMAGE_HEIGHT'],
                         config['IMAGE_WIDTH'], config['channel_number'])
    # Minimum value of tensor [whether normalize 0,1 or -1 to 1
    config['min'] = 0
    config['EPOCHS'] = int(args.epoch_number)
    config['model_save_path'] = Path(args.model_path)
    config['n_classes'] = 1
    config['start_learning_rate'] = float(args.start_learning_rate)
    config['max_learning_rate'] = float(args.max_learning_rate)
    config['min_learning_rate'] = float(args.minimum_learning_rate)
    config['rampup_epochs'] = float(args.rampup_epochs)
    config['sustain_epochs'] = int(args.sustain_epochs)

    # tf.keras.mixed_precision.set_global_policy(
    # "mixed_float16"
    # )
    config['bs'] = int(args.batch_size)
    print(f"{'#'*10}")
    print(f" training count == {config['train_count']}")
    print(f"{'#'*10}")
    config['steps_per_epoch'] = config['train_count']//config['bs']
    config['validation_steps'] = config['test_count']//config['bs']
    print(f"{'#'*10}")
    print(f"batch size == {config['bs']}")
    return config


# %% ../nbs/28_single_pin_training.ipynb 53
def get_pretrained_model(
        args,
        custom_objects: Dict):

    optimizer = tfa.optimizers.AdamW(
        learning_rate=1e-3,
        weight_decay=1e-5,
        clipnorm=1.0)
    loss = CombinedLoss()

    if custom_objects is None:
        custom_objects = {
            'optimizer': optimizer,
            'CombinedLoss': loss,
            # 'focal_tversky_loss_r':focal_tversky_loss_r}
        }

    if args.pretrained():
        loaded_model = tf.keras.models.load_model(
            f"{args.initial_model_path}/{args.initial_model_name}",
            custom_objects=custom_objects
        )

        if args.trn_layer_num > 0:  # we want some layers only
            for i in loaded_model.layers[:int(args.trn_layer_num)]:
                i.trainable = False

            print(f'number of layers is freezed = {args.trn_layer_num}')
        # print(loaded_model.summary())
        print('pretrained model is used')
        return loaded_model

# %% ../nbs/28_single_pin_training.ipynb 54


def get_model(
    args: Dict,
    config: Dict
):
    'get model whether pretrained or from scratch'
    if args.pretrained:
        model = get_pretrained_model(
            args,
            custom_objects=None
        )
    else:
        model = encoder_decoder_small_block(
            input_size=config['im_size'],
            n_classes=config['n_classes']
        )
    return model


# %% ../nbs/28_single_pin_training.ipynb 56
def main(
):
    args = create_parser()
    config = create_config_from_args(args)

    print('model is created')
    model = get_model(args, config)
    # print(model.summary())
    model = training_model(
        config=config,
        model=model,


    )


# %% ../nbs/28_single_pin_training.ipynb 57
if __name__ == '__main__':
    main()
