[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "cv_tools",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "cv_tools"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "cv_tools",
    "section": "Install",
    "text": "Install\ngit clone `git@github.com:HasanGoni/cv_tools.git`\ncd cv_tools\npip install -e . \n\nin case of github is not recognized with ssh then use\n\ngit clone `https://github.com/HasanGoni/cv_tools.git`\ncd cv_tools\npip install -e .",
    "crumbs": [
      "cv_tools"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "cv_tools",
    "section": "How to use",
    "text": "How to use\nyou have a list of filenames with full path, but you are interested to get only the name of the list in a vectorize format\n\nHOME = Path.home()\nDATA_PATH = Path(f'{HOME}/Schreibtisch/projects/data/microscopy')\nMASK_PATH = Path(f'{DATA_PATH}/patch_train_masks/img_0_p_0.png')\nIM_PATH = Path(f'{DATA_PATH}/patch_train_images/img_0_p_0.png')\nDATA_PATH.ls()\n\n(#9) [Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_mask_train_coco_format.json'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_mask_val_coco_format.json'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images.cache'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/train_images'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/data.yaml'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/train_msks'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train')]\n\n\n\npath = Path(fr'{HOME}/Schreibtisch/projects/git_data')  \npath_list = path.ls()\npath_list\n\n(#7) [Path('/home/hasan/Schreibtisch/projects/git_data/senet_segmentation'),Path('/home/hasan/Schreibtisch/projects/git_data/segmentation_test'),Path('/home/hasan/Schreibtisch/projects/git_data/cv_tools_office'),Path('/home/hasan/Schreibtisch/projects/git_data/yolo_v8_segmentation'),Path('/home/hasan/Schreibtisch/projects/git_data/labeling_test'),Path('/home/hasan/Schreibtisch/projects/git_data/rc_files_for_me'),Path('/home/hasan/Schreibtisch/projects/git_data/cv_tools')]\n\n\n\nget_name_(path_list)\n\narray(['fastsetup', 'fine_tune_SAM', 'cv_tools', 'labeling_test'],\n      dtype='&lt;U13')\n\n\n\nReading image in PIL and opencv\n\nSo you have some files, sometimes you wanted read image as opencv and sometimes you wanted to use PIL to read those image\n\n\n# opencv image\nimg = read_img(\n    im_path = IM_PATH,\n    cv=True, # if PIL image just say cv=True, \n    gray=True # in case of color image just use gray=False\n)\n\nIn case you want to see the image\n\nshow_(img)\n\n\n\n\n\n\n\n\nSame way we can see PIL image.\n\n# PIL image\nimg = read_img(\n    im_path = IM_PATH,\n    cv=False, \n    gray=True # in case of color image just use gray=False\n)\n\nPIL image doesnot need show method in jupyter notebook. you can just do following\n\nimg\n\n\n\n\n\n\n\n\n\n\nCropping your image\n\nso you have an image, you want to do centercrop from this image, but you want to make sure, your image has a specific shape\nRemember here you need PIL Image. Opencv image can be easily converted using this Image.fromarray\n\n\nimg.size\n\n(256, 256)\n\n\nour mask has a shape of 256,256, lets centercrop it and make sure it has a shape of 224,224\n\ncrop_mask = center_crop(\n        img, \n        desired_width=224,\n        desired_height=224,\n        height_offset=0,\n        width_offset=0,\n        cv=False\n    )\n\n\nprint(f' crop image has a size of {crop_mask.size}')\ncrop_mask\n\n crop image has a size of (224, 224)\n\n\n\n\n\n\n\n\n\n\nIf expected to have a opencv image, then use cv=True\n\n\ncrop_mask_ocv = center_crop(\n        img, \n        desired_width=224,\n        desired_height=224,\n        height_offset=0,\n        width_offset=0,\n        cv=True\n    )\n\n\nshow_(crop_mask_ocv)\n\n\n\n\n\n\n\n\n\nOverlay Image and Mask\n\nIn case of want to see overlay imagea and mask in a same image\n\n\noverlay_mask(\n    im_path=IM_PATH,\n    msk_path=MASK_PATH,\n    alpha=0.3 # visibility opacity\n)\n\n\n\n\n\n\n\n\n\nSometimes one needs to see not the mask but the border line of the mask\n\n\noverlay_mask_border_on_image(\n    im_path=IM_PATH,\n    msk_path=MASK_PATH,\n    save_new_img_path=None, # in case you want to save overlay mask then give path name\n    border_width=1,\n    show_=True\n\n)\n\n\n\n\n\n\n\n\n\nSometimes you want to compare another image to the overlay image, then just use this image\njust an example we are adding the mask again\n\n\nnew_image = cv2.cvtColor(read_img(IM_PATH, cv=True), cv2.COLOR_GRAY2RGB)\n\n\nnew_image.shape\n\n(256, 256, 3)\n\n\n\noverlay_mask_border_on_image(\n    im_path=IM_PATH,\n    msk_path=MASK_PATH,\n    new_img=new_image,\n    save_new_img_path=None, # in case you want to save this new image\n    border_width=1,\n    show_=True\n\n)\n\n\n\n\n\n\n\n\n\n\nConcatenating images\n\nSometimes you have 2 or more images, and you want to create a single image from these images\nif desired one small text can be added in this new image\n\n\nimages = [new_image, new_image]\n\n\ncombined_img = concat_images(\n    images= images,\n    rows=1,\n    cols=2,\n    number='combined'\n)\n\n\nshow_(combined_img)\n\n\n\n\n\n\n\n\n\ncombined_img = concat_images(\n    images= images,\n    rows=2,\n    cols=1,\n    number='combined'\n)\n\n\nshow_(combined_img)\n\n\n\n\n\n\n\n\n\nSo you have one image where could be lots of masks or single masks, you doesn’t want to see full image, but only mask part of the image, with image\n\n\nIM_PATH.parent\n\nPath('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images')\n\n\n\nshow_poster_from_path(\n    mask_path=MASK_PATH,\n    im_path=IM_PATH.parent, # Remember here not the full image path,\\\n                        #but only folder name, from this folder \n                        # Same file name as mask_path name will be\n                        # searched\n    show_='poster', # only mask\n    text='test_poster'\n)\n\nerror: OpenCV(4.8.1) /io/opencv/modules/imgproc/src/resize.cpp:4065: error: (-215:Assertion failed) inv_scale_x &gt; 0 in function 'resize'\n\n\n\nIn case of single poster, it is not helpful, When you have lot’s of small objects, then may be it is interesting\n\n\n\nGet Template part from an image\n\nSo you have a template image, and you want to get this template from this image,\nfollowing function will give bounding box (x, y, w, h format) of template part from this image\n\n\nx, y, w, h=get_template_part(\n    img=read_img(IM_PATH, cv=True),\n    tmp_img=tmp_im_path\n)\ntmp_part = img[y:y +h, x: x+w]\n\n\n\nFinding contour from a binary mask\n\nimg = read_img(IM_PATH, cv=True, gray=True)\n\n\ncontours = find_contours_binary(\n    img\n)\nlen(contours)\n\n1\n\n\n\n\nApply multiple thresholding in an image\n\nYou have any image, and you want to segment it based on its value\n\n\nimg = read_img(IM_PATH, cv=True, gray=True)\n\n\nthrs_img = multi_otsu(img, classes=3)\n\n\nshow_(thrs_img)\n\n\n\n\n\n\n\n\n\n\nSplit Image\n\nSo you have an image, and you want to cut your images in smaller parts.\nlast part will not be same like other parts, because possible extra part or smaller part\n\n\nsplitted_parts = split_image(img, num_splits=3, direction='horizontal')\nshow_(splitted_parts)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsplitted_parts_v = split_image(img, num_splits=3, direction='vertical')\nshow_(splitted_parts_v)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrection of Masks\n\nSo you have a binary mask, but there are some small holes in that mask\nso want to fill those holes inside your mask\n\n\nfilled_mask = fill_holes_in_objects(binaray_mask)\n\n\nSometimes you have some smaller parts in your masks and you want to remove those smaller parts from the mask\n\n\nremove_small_objects(\n    binary_mask=binary_mask,\n    size_threshold=size_threshold\n)\n\n\nMay be you want to see each object in the mask put a number in each object and based on this number, you just remove a object from the mask\n\n\nlabels, new_labels = show_labeled_mask(\n    msk_path\n)\n\n\nremove_object_from_mask(mask, object_id_list=[1])\n\n\n\ncheck data\n\nin case of check validity of mask, you can create a overlay mask and check if it is correct or not,\n\noverlay_mask_path - is the saved image path\nmove_path - is the path where you want to move the mask ( in case of mask is not correct)\nim_height - height of the image\n\n\n\ndisplay_image_row(\n    im_path=overlay_mask_path,\n    move_path=move_path,\n    max_images=10,\n    start=0,\n    im_height=200,\n    im_width=200,\n\n)",
    "crumbs": [
      "cv_tools"
    ]
  },
  {
    "objectID": "index.html#compress-and-filter",
    "href": "index.html#compress-and-filter",
    "title": "cv_tools",
    "section": "Compress and filter",
    "text": "Compress and filter\n\nim_path = Path(r'/home/ai_sintercra.work/Fail_start20240402/_unzip/main_im2_cropped')\nmsk_path = Path(im_path.parent, 'main_im2_cropped_masks')\nconvert_image_to_parquet_p(\n    im_path=im_path,\n    file_name_func=None,\n    file_exts='.png',\n    threadpool=False)",
    "crumbs": [
      "cv_tools"
    ]
  },
  {
    "objectID": "compress_and_filter_data.html",
    "href": "compress_and_filter_data.html",
    "title": "Compress and filter",
    "section": "",
    "text": "Compress the data and save them in pyarrow format, so that easy can be transferred and filter them\n\n\nsource\n\napply_functions\n\n apply_functions (fn:Union[pathlib.Path,str],\n                  functions:Optional[List[Callable]]=None)\n\nApply a list of functions to a file\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfn\ntyping.Union[pathlib.Path, str]\n\nName fo the file\n\n\nfunctions\ntyping.Optional[typing.List[typing.Callable]]\nNone\n\n\n\n\n\nsource\n\n\nprocess_image\n\n process_image (im, file_name_func)\n\n\nsource\n\n\nconvert_images_to_parquet\n\n convert_images_to_parquet (image_directory:Union[str,pathlib.Path],\n                            output_file:Union[str,pathlib.Path],\n                            file_name_func:List[Callable]=None,\n                            file_exts:str='.png')\n\nConvert images in a directory to a parquet file\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimage_directory\ntyping.Union[str, pathlib.Path]\n\ndirectory containing images\n\n\noutput_file\ntyping.Union[str, pathlib.Path]\n\noutput parquet file\n\n\nfile_name_func\ntyping.List[typing.Callable]\nNone\nfunctions to apply to the filename\n\n\nfile_exts\nstr\n.png\n\n\n\n\n\ndata_path = os.getenv('DATA_PATH')\n\n\nim_src = Path(f'{data_path}/easy_front/Cropped_Images_png')\n\nconvert_images_to_parquet(im_src, f'{data_path}/easy_front/Cropped_Images.parquet')\n\n\n\n\n\nsource\n\n\nconvert_image_to_parquet_p\n\n convert_image_to_parquet_p (im_path:Union[str,pathlib.Path],\n                             file_name_func:List[Callable]=None,\n                             file_exts:str='.png', threadpool:bool=True,\n                             num_workers:int=16, chunksize:int=1)\n\nConvert images in a directory to a parquet file parallell\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nim_path\ntyping.Union[str, pathlib.Path]\n\npath of images\n\n\nfile_name_func\ntyping.List[typing.Callable]\nNone\nfunctions to apply to the filename\n\n\nfile_exts\nstr\n.png\nfile extensions\n\n\nthreadpool\nbool\nTrue\nuse threadpool\n\n\nnum_workers\nint\n16\nnumber of workers\n\n\nchunksize\nint\n1\nchunksize\n\n\n\n\ndef example_metadata_extractor(filename):\n    if \"A\" in filename:\n        return \"A_type_pin\"\n    return \"B_type_pin\"\n\n\nconvert_images_to_parquet(im_src, f'{data_path}/easy_front/Cropped_Images.parquet', file_name_func=[example_metadata_extractor])\n\n\n\n\n\nsource\n\n\nfilter_images\n\n filter_images (parquet_file, condition)\n\n\npin_a_images = filter_images(f'{data_path}/easy_front/Cropped_Images.parquet', 'A_type_pin')\n\n\npin_a_images.head()\n\n\n\n\n\n\n\n\n\nfilename\nimage_data\nexample_metadata_extractor\n\n\n\n\n0\n2_1_CroppedImg_20231018_92536201_5_A.png\nb'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...\nA_type_pin\n\n\n2\n2_1_CroppedImg_20231018_92536201_25_A.png\nb'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...\nA_type_pin\n\n\n3\n2_2_CroppedImg_20231018_92536201_24_A.png\nb'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...\nA_type_pin\n\n\n5\n0_1_CroppedImg_20231018_92042317_7_A.png\nb'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...\nA_type_pin\n\n\n7\n2_2_CroppedImg_20231018_92536201_17_A.png\nb'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...\nA_type_pin",
    "crumbs": [
      "Compress and filter"
    ]
  },
  {
    "objectID": "cv_ops.html",
    "href": "cv_ops.html",
    "title": "Computer vision operation",
    "section": "",
    "text": "Different computer vision operations will be implemented here\n\n\nsource\n\nmulti_otsu\n\n multi_otsu (img:&lt;built-infunctionarray&gt;, classes:int=3)\n\nMulti-Otsu thresholding-&gt; returns image of type np.uint8\n\nsource\n\n\nremove_small_objects\n\n remove_small_objects (binary_mask:numpy.ndarray,\n                       size_threshold:Union[float,int])\n\nFrom a binary mask remove small objects\n\n\n\n\nType\nDetails\n\n\n\n\nbinary_mask\nndarray\nnp.ndarry\n\n\nsize_threshold\ntyping.Union[float, int]\n\n\n\n\n\nsource\n\n\nfill_holes_in_objects\n\n fill_holes_in_objects (binary_mask)\n\nFill holes inside binary mask\n\nsource\n\n\nconvert_to_rotated_rectangles\n\n convert_to_rotated_rectangles (binary_mask)\n\nConvert binary mask arbitary from to rotated rectange",
    "crumbs": [
      "Computer vision operation"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nPath.filter_\n\n Path.filter_ (name_part:str)\n\nfilter based on name_part in file\n\nsource\n\n\nlabel_mask\n\n label_mask (mask:numpy.ndarray)\n\nLabel connected components in a binary mask\n\nsource\n\n\nshow_labeled_mask\n\n show_labeled_mask (msk_path)\n\n\nsource\n\n\nwrite_new_mask\n\n write_new_mask (new_lb, new_mask_path, fn)\n\nWrite mask to new_mask_path\n\n\n\n\nDetails\n\n\n\n\nnew_lb\nlabeled masks\n\n\nnew_mask_path\npath to save the new mask\n\n\nfn\nname of the image\n\n\n\n\nsource\n\n\nremove_object_from_mask\n\n remove_object_from_mask (mask:numpy.ndarray, object_id_list:List[int])\n\nRemove object from mask.\n\nsource\n\n\nread_img\n\n read_img (im_path:Union[str,pathlib.Path], cv:bool=True, gray:bool=True)\n\nRead image from name could be open cv or pil image\n\nsource\n\n\nshow_\n\n show_ (im_path:Union[str,numpy.ndarray])\n\nShowing an image could be image or str,\n\nsource\n\n\ncenter_crop\n\n center_crop (image:&lt;module'PIL.Image'from'/opt/hostedtoolcache/Python/3.9\n              .19/x64/lib/python3.9/site-packages/PIL/Image.py'&gt;,\n              desired_width:int=1632, desired_height:int=1152,\n              height_offset:int=-50, width_offset:int=-70, cv:bool=True)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimage\nPIL.Image\n\nnot open cv but PIL Image\n\n\ndesired_width\nint\n1632\n\n\n\ndesired_height\nint\n1152\n\n\n\nheight_offset\nint\n-50\n\n\n\nwidth_offset\nint\n-70\n\n\n\ncv\nbool\nTrue\n\n\n\n\n\nsource\n\n\noverlay_mask\n\n overlay_mask (im_path:Union[str,pathlib.Path],\n               msk_path:Union[str,pathlib.Path],\n               overlay_clr:Tuple[int,int,int]=(0, 1, 0), scale:int=1,\n               alpha:float=0.5)\n\nCreaete a overlay image from image and mask\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nim_path\ntyping.Union[str, pathlib.Path]\n\n\n\n\nmsk_path\ntyping.Union[str, pathlib.Path]\n\n\n\n\noverlay_clr\ntyping.Tuple[int, int, int]\n(0, 1, 0)\ncolor\n\n\nscale\nint\n1\nto scale the image\n\n\nalpha\nfloat\n0.5\nvisibility\n\n\n\n\nsource\n\n\noverlay_mask_border_on_image\n\n overlay_mask_border_on_image (im_path:Union[pathlib.Path,str],\n                               msk_path:Union[pathlib.Path,str], save_new_\n                               img_path:Union[pathlib.Path,str]=None, save\n                               _overlay_img_path:Union[pathlib.Path,str]=N\n                               one, new_img:Union[List,numpy.ndarray,NoneT\n                               ype]=None, scale_:int=1,\n                               border_color:Tuple[int,int,int]=(0, 1, 0),\n                               border_width:int=1, show_:bool=False)\n\n*Overlays the border of a binary mask on a grayscale image and displays the result using matplotlib.\nArgs: image (numpy.ndarray): Grayscale image. mask (numpy.ndarray): Binary mask of the same size as the image. border_color (tuple): RGB color for the mask border in the range [0, 1]. border_width (int): Width of the border.\nReturns: None: The function displays a plot.*\n\nsource\n\n\noverlay_mask_border_on_image_frm_img\n\n overlay_mask_border_on_image_frm_img\n                                       (img:Union[OpenCvImage,PIL.Image.Im\n                                       age], msk:Union[OpenCvImage,PIL.Ima\n                                       ge.Image])\n\nOverlay mask border on image from image\n\nsource\n\n\nconcat_images\n\n concat_images (images:List[numpy.ndarray], rows:int, cols:int,\n                number:str)\n\nConcate images rows and cols and add a number to the image.\n\n\n\n\nType\nDetails\n\n\n\n\nimages\ntyping.List[numpy.ndarray]\n\n\n\nrows\nint\nnumber of rows\n\n\ncols\nint\nnumber of columns in combined images\n\n\nnumber\nstr\na text which will be inserted in the combined image\n\n\n\n\nsource\n\n\nshow_poster_from_path\n\n show_poster_from_path (mask_path:str, im_path:str, show_:str, text:str,\n                        scale=1)\n\nShow only masked part of the image or full image with mask\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmask_path\nstr\n\n\n\n\nim_path\nstr\n\nname of the image fodler , e.g. ‘images’ or ‘X’\n\n\nshow_\nstr\n\nwhether to show image, mask, poster\n\n\ntext\nstr\n\ntext in image\n\n\nscale\nint\n1\n\n\n\n\n\nsource\n\n\nseamless_clone\n\n seamless_clone (full_img:&lt;function OpenCvImage&gt;, replace_part:&lt;function\n                 OpenCvImage&gt;, center:Tuple[int,int],\n                 clone_method:str='normal')\n\nReplace some part of full_img with replace_part object\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfull_img\nOpenCvImage\n\ngray scale image\n\n\nreplace_part\nOpenCvImage\n\ngray scale image\n\n\ncenter\ntyping.Tuple[int, int]\n\ncenter position in full_img #where the replace_part will be placed\n\n\nclone_method\nstr\nnormal\n\n\n\n\n\nsource\n\n\nget_template_part\n\n get_template_part (img:numpy.ndarray, tmp_img:numpy.ndarray)\n\nGet bounding box coordinate from the image (x,y, w, h format)\n\n\n\n\nType\nDetails\n\n\n\n\nimg\nndarray\nopencv image\n\n\ntmp_img\nndarray\nopencv image\n\n\n\n\nsource\n\n\nsplit_image\n\n split_image (img:numpy.ndarray, num_splits:int, direction:str)\n\nSplit an image into different parts\n\n\n\n\nType\nDetails\n\n\n\n\nimg\nndarray\n\n\n\nnum_splits\nint\n\n\n\ndirection\nstr\nhorizontal or vertical\n\n\n\n\nsource\n\n\nsplit_image_with_coordinates\n\n split_image_with_coordinates (img:numpy.ndarray, num_splits:int,\n                               direction:str)\n\nSplit an image with different parts in different coordinates\n\nsource\n\n\ncreate_same_shape\n\n create_same_shape (src_img:numpy.ndarray, dst_img:numpy.ndarray)\n\nCreate same shape of dst image like src_img\n\n\n\n\nType\nDetails\n\n\n\n\nsrc_img\nndarray\nimage which size needs to be replicated\n\n\ndst_img\nndarray\nimage which needs to resized\n\n\n\n\nsource\n\n\nget_circle_from_single_pin\n\n get_circle_from_single_pin (sn_pin_img:numpy.ndarray)\n\nGet the circle from single pin image\n\nsource\n\n\nfind_contours_binary\n\n find_contours_binary (img:numpy.ndarray)\n\nReturn contours from the binary image\n\n\n\n\nType\nDetails\n\n\n\n\nimg\nndarray\nbinary image\n\n\n\n\nsource\n\n\nadjust_brightness\n\n adjust_brightness (img:numpy.ndarray, alpha:float)\n\nAdjust the brightness of the image\n\n\n\n\nType\nDetails\n\n\n\n\nimg\nndarray\nimage to adjust brightness\n\n\nalpha\nfloat\nalpha &gt; 1 to brighten; alpha &lt; 1 to darken\n\n\n\n\nsource\n\n\nssim_\n\n ssim_ (img1:numpy.ndarray, img2:numpy.ndarray, win_size:int=5)\n\nCompare structural similarity between two images\n\nsource\n\n\norb_sim_\n\n orb_sim_ (img1:numpy.ndarray, img2:numpy.ndarray)\n\nCompare ORB similarity between two images\n\nsource\n\n\nfrm_cntr_to_bbox\n\n frm_cntr_to_bbox (cntr)\n\n\nsource\n\n\nfoo\n\n foo ()",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "dataset_check.html",
    "href": "dataset_check.html",
    "title": "dataset check",
    "section": "",
    "text": "Before or after training, we want to check dataset, this checking functionality will be used here\n\n\nsource\n\ndisplay_image_row\n\n display_image_row (im_path:Union[pathlib.Path,str],\n                    move_path:Union[pathlib.Path,str], max_images:int=10,\n                    start:int=0, im_height:int=100, im_width:int=100)\n\n\nHOME = Path.home()\ncrop_im_path = Path(fr'{HOME}/Schreibtisch/projects/data/easy_front/Cropped_Images_png')\nmove_path = Path(fr'{HOME}/Schreibtisch/projects/data/easy_front/move_path_old')\nmask_path = Path(fr'{HOME}/Schreibtisch/projects/data/easy_front/per_sam_masks')\noverlay_mask_path = Path(fr'{HOME}/Schreibtisch/projects/data/easy_front/overlay_masks_old_data')\noverlay_mask_path.mkdir(exist_ok=True, parents=True)\ncrop_im_path.ls(), mask_path.ls()\n\n((#1639) [Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/2_1_CroppedImg_20231018_92536201_5_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/1_4_CroppedImg_20231018_92329777_33_B.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/2_1_CroppedImg_20231018_92536201_25_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/2_2_CroppedImg_20231018_92536201_24_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/3_4_CroppedImg_20231018_92716715_21_B.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/0_1_CroppedImg_20231018_92042317_7_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/3_3_CroppedImg_20231018_92716715_26_B.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/2_2_CroppedImg_20231018_92536201_17_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/0_1_CroppedImg_20231018_92042317_39_B.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/Cropped_Images_png/2_2_CroppedImg_20231018_92536201_12_A.png')...],\n (#1482) [Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/2_1_CroppedImg_20231018_92536201_5_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/1_4_CroppedImg_20231018_92329777_33_B.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/2_1_CroppedImg_20231018_92536201_25_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/2_2_CroppedImg_20231018_92536201_24_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/3_4_CroppedImg_20231018_92716715_21_B.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/0_1_CroppedImg_20231018_92042317_7_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/3_3_CroppedImg_20231018_92716715_26_B.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/2_2_CroppedImg_20231018_92536201_17_A.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/0_1_CroppedImg_20231018_92042317_39_B.png'),Path('/home/user/Schreibtisch/projects/data/easy_front/per_sam_masks/2_2_CroppedImg_20231018_92536201_12_A.png')...])",
    "crumbs": [
      "dataset check"
    ]
  }
]